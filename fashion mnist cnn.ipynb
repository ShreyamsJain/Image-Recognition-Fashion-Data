{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_train = numpy.genfromtxt(\"fashionmnist/fashion-mnist_train.csv\", delimiter=\",\", dtype=None, names=True)\n",
    "dataset_test = numpy.genfromtxt(\"fashionmnist/fashion-mnist_test.csv\", delimiter=\",\", dtype=None, names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"fashionmnist/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"fashionmnist/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:, 1:785].values\n",
    "y = train_df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray')) \n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray')) \n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray')) \n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') \n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(28, 28, 1),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), padding=\"valid\", activation=\"relu\", input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      " - 37s - loss: 0.5567 - acc: 0.8063 - val_loss: 0.3853 - val_acc: 0.8648\n",
      "Epoch 2/10\n",
      " - 40s - loss: 0.3742 - acc: 0.8679 - val_loss: 0.3417 - val_acc: 0.8805\n",
      "Epoch 3/10\n",
      " - 38s - loss: 0.3246 - acc: 0.8854 - val_loss: 0.3046 - val_acc: 0.8934\n",
      "Epoch 4/10\n",
      " - 36s - loss: 0.3015 - acc: 0.8934 - val_loss: 0.2969 - val_acc: 0.8926\n",
      "Epoch 5/10\n",
      " - 41s - loss: 0.2774 - acc: 0.9015 - val_loss: 0.2751 - val_acc: 0.9040\n",
      "Epoch 6/10\n",
      " - 42s - loss: 0.2605 - acc: 0.9054 - val_loss: 0.2688 - val_acc: 0.9020\n",
      "Epoch 7/10\n",
      " - 37s - loss: 0.2486 - acc: 0.9095 - val_loss: 0.2748 - val_acc: 0.9014\n",
      "Epoch 8/10\n",
      " - 38s - loss: 0.2338 - acc: 0.9144 - val_loss: 0.2634 - val_acc: 0.9061\n",
      "Epoch 9/10\n",
      " - 49s - loss: 0.2199 - acc: 0.9194 - val_loss: 0.2493 - val_acc: 0.9125\n",
      "Epoch 10/10\n",
      " - 36s - loss: 0.2064 - acc: 0.9250 - val_loss: 0.2497 - val_acc: 0.9129\n",
      "CNN Error: 8.71%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (5, 5), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (3, 3), activation=\"relu\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      " - 35s - loss: 0.8019 - acc: 0.7038 - val_loss: 0.5099 - val_acc: 0.8162\n",
      "Epoch 2/10\n",
      " - 37s - loss: 0.5008 - acc: 0.8154 - val_loss: 0.4385 - val_acc: 0.8433\n",
      "Epoch 3/10\n",
      " - 36s - loss: 0.4386 - acc: 0.8419 - val_loss: 0.3794 - val_acc: 0.8645\n",
      "Epoch 4/10\n",
      " - 38s - loss: 0.4048 - acc: 0.8538 - val_loss: 0.3651 - val_acc: 0.8693\n",
      "Epoch 5/10\n",
      " - 36s - loss: 0.3786 - acc: 0.8631 - val_loss: 0.3324 - val_acc: 0.8822\n",
      "Epoch 6/10\n",
      " - 37s - loss: 0.3566 - acc: 0.8702 - val_loss: 0.3348 - val_acc: 0.8798\n",
      "Epoch 7/10\n",
      " - 36s - loss: 0.3437 - acc: 0.8762 - val_loss: 0.3211 - val_acc: 0.8859\n",
      "Epoch 8/10\n",
      " - 37s - loss: 0.3301 - acc: 0.8801 - val_loss: 0.2984 - val_acc: 0.8932\n",
      "Epoch 9/10\n",
      " - 35s - loss: 0.3203 - acc: 0.8833 - val_loss: 0.2962 - val_acc: 0.8951\n",
      "Epoch 10/10\n",
      " - 41s - loss: 0.3091 - acc: 0.8852 - val_loss: 0.2853 - val_acc: 0.8983\n",
      "Large CNN Error: 10.17%\n"
     ]
    }
   ],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, input_shape=(28, 28, 1), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model_larger = larger_model()\n",
    "# Fit the model\n",
    "model_larger.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model_larger.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
